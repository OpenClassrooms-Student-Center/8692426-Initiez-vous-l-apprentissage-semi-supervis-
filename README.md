# Initiez-vous Ã  l'apprentissage semi-supervisÃ© (SSL) ğŸš€

Apprenez les bases et les techniques avancÃ©es de l'apprentissage semi-supervisÃ© Ã  travers une sÃ©rie de notebooks guidÃ©s. Ce dÃ©pÃ´t est pensÃ© pour les Ã©tudiantÂ·eÂ·s curieuxÂ·ses qui veulent comprendre, expÃ©rimenter et s'amuser avec le SSL.

---

## Pourquoi le SSL ? ğŸ¤”

En apprentissage supervisÃ©, on a besoin de beaucoup de donnÃ©es Ã©tiquetÃ©esâ€¦ ce qui coÃ»te cher. En non supervisÃ©, on n'utilise pas les labels. Le semi-supervisÃ© (SSL) combine le meilleur des deux mondes: il exploite un petit jeu de donnÃ©es labellisÃ© et un grand jeu non labellisÃ© pour amÃ©liorer les performances.

IdÃ©es clÃ©s que vous verrez ici:
- **Propagation de labels**: diffuser l'information des Ã©tiquettes via les voisins dans un graphe.
- **RÃ©gularisation par cohÃ©rence**: encourager le modÃ¨le Ã  Ãªtre stable sous perturbations (bruit, augmentations).
- **Pseudo-labeling**: utiliser les prÃ©dictions du modÃ¨le comme pseudo-labels sur les donnÃ©es non-labellisÃ©es.
- **MÃ©thodes SOTA**: MixMatch, FixMatch, FlexMatch.
- **GANs semi-supervisÃ©s**: tirer parti des gÃ©nÃ©rateurs pour mieux classifier.

---

## Contenu du dÃ©pÃ´t ğŸ“š

Les notebooks sont en franÃ§ais et indÃ©pendants. Parcourez-les dans l'ordre suggÃ©rÃ© ou piochez selon vos besoins.

- `ssl_notebook.ipynb` â€” Panorama du SSL, principes, pipeline type, premiÃ¨res expÃ©riences.
- `La Propagation de Labels, ou l'art de juger une image par ses voisins.ipynb` â€” Label Propagation/Spreading, similaritÃ©s, graphes, intuition et dÃ©mos.
- `La RÃ©gularisation par CohÃ©rence, ou l'art d'Ãªtre constant avec soi-mÃªme.ipynb` â€” Consistency regularization, augmentations, objectifs de stabilitÃ©.
- `Le Pseudo-Labeling, ou l'art de faire confiance Ã  son modÃ¨le.ipynb` â€” Pseudo-labels, seuils de confiance, itÃ©rations.
- `Advanced SSL Techniques - FixMatch, FlexMatch, and MixMatch.ipynb` â€” ImplÃ©mentations et concepts des mÃ©thodes rÃ©centes.
- `Les Semi-Supervised GANs, ou l'art de gÃ©nÃ©rer pour mieux classer.ipynb` â€” Cadre GAN pour le SSL et exemples guidÃ©s.
- `dermamnist_ssl_model.pth` â€” Exemple de poids entraÃ®nÃ©s (DermMNIST) pour illustrer l'infÃ©rence/Ã©valuation.

Note: Certains notebooks peuvent tÃ©lÃ©charger automatiquement des petits jeux de donnÃ©es ou expliquer comment les obtenir.

---

## PrÃ©requis ğŸ§°

- Python 3.9+ recommandÃ©
- Jupyter (Notebook ou Lab)
- BibliothÃ¨ques usuelles: NumPy, pandas, scikit-learn, matplotlib/seaborn
- Deep learning: PyTorch ou TensorFlow selon les notebooks (la majoritÃ© est orientÃ©e PyTorch)

S'il n'y a pas de `requirements.txt`, installez au besoin depuis les erreurs import (les notebooks rappellent gÃ©nÃ©ralement les dÃ©pendances).

---

## Installation rapide âš™ï¸

Option 1 â€” Environnement virtuel minimal:

```bash
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install jupyter numpy pandas scikit-learn matplotlib seaborn torch torchvision torchaudio
```

Option 2 â€” Conda:

```bash
conda create -n ssl python=3.10 -y
conda activate ssl
pip install jupyter numpy pandas scikit-learn matplotlib seaborn torch torchvision torchaudio
```

---

## DÃ©marrage ğŸ

1. Lancez Jupyter:
   ```bash
   jupyter lab
   # ou
   jupyter notebook
   ```
2. Ouvrez les notebooks dans le dossier: `.../8692426-Initiez-vous-l-apprentissage-semi-supervis-/`.
3. ExÃ©cutez les cellules dans l'ordre. Lisez les explications entre les blocs de code.

Astuce: si un import Ã©choue, installez le paquet manquant avec `pip install <paquet>` puis relancez le noyau.

---

## Parcours d'apprentissage conseillÃ© ğŸ—ºï¸

1. `ssl_notebook.ipynb` â€” Comprendre les motivations et le pipeline gÃ©nÃ©ral.
2. Graph-based SSL â€” Propagation de labels.
3. Consistency regularization â€” Perturbations et objectifs de stabilitÃ©.
4. Pseudo-labeling â€” Auto-enseignement sur donnÃ©es non-labelisÃ©es.
5. MÃ©thodes avancÃ©es â€” MixMatch, FixMatch, FlexMatch.
6. Bonus â€” GANs semi-supervisÃ©s.

Vous pouvez ensuite revenir sur vos jeux de donnÃ©es et adapter les techniques vues pour vos projets.

---

## Conseils pour de bons rÃ©sultats ğŸ’¡

- **QualitÃ© des augmentations**: en SSL moderne (FixMatch/FlexMatch), les choix d'augmentations fortes sont dÃ©terminants.
- **Seuils de confiance**: ajustez-les pour contrÃ´ler le bruit des pseudo-labels.
- **Balance labellisÃ©/non-labellisÃ©**: surveillez les ratios dans les batchs.
- **Validation**: gardez un petit set validÃ© pour suivre l'apprentissage sans fuite d'information.
- **ReproductibilitÃ©**: fixez les seeds quand vous comparez des mÃ©thodes.

---

## DÃ©pannage ğŸ› ï¸

- ProblÃ¨mes CUDA/GPU: commencez en CPU en retirant `.to(device)`/`cuda()` ou en forÃ§ant `device='cpu'`.
- ImportError: installez le paquet manquant. VÃ©rifiez les versions de PyTorch compatibles avec votre CUDA.
- MÃ©moire insuffisante: rÃ©duisez la taille des batchs et/ou les dimensions des images.

---

## Ressources pour aller plus loin ğŸ“–

- MixMatch: Beyond Empirical Risk Minimization (Berthelot et al., 2019)
- FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence (Sohn et al., 2020)
- FlexMatch: Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling (Zhang et al., 2021)
- Semi-Supervised Learning (Chapelle, Scholkopf, Zien) â€” le classique

Ces rÃ©fÃ©rences complÃ¨tent les intuitions dÃ©veloppÃ©es dans les notebooks.

---

## Remerciements ğŸ™Œ

Ce dÃ©pÃ´t a pour but de vous guider pas Ã  pas. N'hÃ©sitez pas Ã  expÃ©rimenter, casser, recommencerâ€¦ c'est comme Ã§a qu'on apprend ! Bon apprentissage semi-supervisÃ© âœ¨