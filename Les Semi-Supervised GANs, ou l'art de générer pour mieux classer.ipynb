{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les semi-supervised GANs, ou l'art de g√©n√©rer pour mieux classer\n",
    "\n",
    "Bienvenue dans ce chapitre d√©di√© aux Semi-Supervised Generative Adversarial Networks (SGANs) ! Apr√®s avoir explor√© le pseudo-labeling (qui se fie aux pr√©dictions confiantes du mod√®le) et la propagation de labels (qui exploite les similarit√©s entre images via des graphes), on passe √† une approche plus 'cr√©ative' : utiliser des r√©seaux adversariaux pour g√©n√©rer de nouvelles donn√©es et am√©liorer la classification.\n",
    "\n",
    "    Imaginez deux agents en comp√©tition : l'un (le g√©n√©rateur) cr√©e de fausses images pour tromper l'autre (le discriminateur), qui doit non seulement d√©tecter les faux, mais aussi classer les vraies images. Cette 'bataille' permet d'apprendre des repr√©sentations riches, m√™me avec peu de labels !\n",
    "\n",
    "Les SGANs √©tendent les GANs classiques au semi-supervis√© : le discriminateur pr√©dit √† la fois 'vrai/faux' et la classe pour les images vraies. Cela permet d'utiliser les donn√©es non √©tiquet√©es pour renforcer l'apprentissage non supervis√© (vrai vs faux), et les √©tiquet√©es pour la supervision.\n",
    "\n",
    "Pourquoi SGAN ? Dans les contextes comme DermaMNIST, o√π les labels sont rares et co√ªteux (besoin d'experts m√©dicaux), g√©n√©rer de donn√©es vari√©es aide le mod√®le √† mieux g√©n√©raliser sans ajouter de bruit comme dans le pseudo-labeling.\n",
    "\n",
    "Compr√©hension cl√© de la strat√©gie SGAN :\n",
    "\n",
    "    Pour les donn√©es √©tiquet√©es : On corrige le discriminateur (D) pour pr√©dire la bonne classe (0 √† 6) avec une perte supervis√©e, car on conna√Æt la v√©rit√©.\n",
    "    Pour les donn√©es non √©tiquet√©es : On corrige D pour les classer comme 'r√©elles' (somme des probabilit√©s des classes 0 √† 6 √©lev√©e), sans pr√©ciser la classe exacte. C'est une correction 'binaire' : si D les place entre 0 et 6, c'est bien ; si en 7 ('faux'), c'est mal, car ce sont des images r√©elles.\n",
    "    Pour les images g√©n√©r√©es (fausses) : On corrige D pour les classer comme 'fausses' (classe 7). Si D les place en 0 √† 6, c'est mal ; l'objectif est de maximiser la probabilit√© de la classe 7.\n",
    "    Le g√©n√©rateur (G) veut l'inverse : tromper D en faisant passer ses fausses images pour r√©elles (probabilit√©s √©lev√©es en 0 √† 6).\n",
    "\n",
    "Objectifs p√©dagogiques :\n",
    "\n",
    "    üß† Comprendre les GANs et leur adaptation au semi-supervis√©.\n",
    "    üõ†Ô∏è Impl√©menter un G√©n√©rateur et un Discriminateur simples.\n",
    "    ‚öîÔ∏è Mettre en place la boucle d'entra√Ænement adversariale.\n",
    "    üìä √âvaluer le Discriminateur comme classificateur et comparer aux m√©thodes pr√©c√©dentes.\n",
    "    üé® Visualiser les images g√©n√©r√©es pour voir ce que le mod√®le 'imagine'.\n",
    "\n",
    "On r√©utilise notre setup de DermaMNIST avec 350 images √©tiquet√©es (50 par classe). Pr√™ts √† lancer la d√©mo ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pr√©paration de l'environnement et des donn√©es\n",
    "\n",
    "On r√©utilise le code de chargement de DermaMNIST des chapitres pr√©c√©dents. Si vous avez saut√© les √©tapes, ex√©cutez d'abord P1C3 ou P1C4 pour avoir les variables comme `train_dataset`, `labeled_indices`, etc. Ici, on assume qu'elles sont d√©finies.\n",
    "\n",
    "Rappel de la strat√©gie SGAN : Les donn√©es √©tiquet√©es servent √† la perte supervis√©e (correction pr√©cise sur la classe connue), les non √©tiquet√©es √† la perte non supervis√©e (correction pour 'r√©el', i.e. classes 0-6), et les g√©n√©r√©es √† renforcer la d√©tection des faux (classe 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "\n",
    "# Pour la reproductibilit√©, parce qu'on est des gens s√©rieux\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset charg√© : dermamnist\n",
      "Type de t√¢che : multi-class\n",
      "Nombre de canaux : 3\n",
      "Nombre de classes : 7\n",
      "Taille du jeu d'entra√Ænement : 7007\n",
      "Taille du jeu de test : 2005\n"
     ]
    }
   ],
   "source": [
    "# Nom du dataset √† charger\n",
    "data_flag = 'dermamnist'\n",
    "# R√©cup√®re les informations sp√©cifiques √† ce dataset depuis medmnist\n",
    "info = INFO[data_flag]\n",
    "\n",
    "# Ajout de prints pour mieux comprendre le dataset\n",
    "print(f\"Dataset charg√© : {data_flag}\")\n",
    "\n",
    "# Extrait le type de t√¢che (classification, r√©gression, etc.)\n",
    "task = info['task']\n",
    "print(f\"Type de t√¢che : {task}\")\n",
    "\n",
    "# Extrait le nombre de canaux des images (3 pour RGB, 1 pour niveaux de gris)\n",
    "n_channels = info['n_channels']\n",
    "print(f\"Nombre de canaux : {n_channels}\")\n",
    "\n",
    "# Extrait le nombre de classes pour la classification\n",
    "n_classes = len(info['label'])\n",
    "print(f\"Nombre de classes : {n_classes}\")\n",
    "\n",
    "# R√©cup√®re la classe Python sp√©cifique pour ce dataset\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "# Transformations: on s√©pare train/test et on ajoute des augmentations l√©g√®res pour mieux g√©n√©raliser\n",
    "# Normalisation explicite 3 canaux\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Charge les datasets d'entra√Ænement et de test\n",
    "train_dataset = DataClass(split='train', transform=transform_train, download=True)\n",
    "test_dataset = DataClass(split='test', transform=transform_test, download=True)\n",
    "\n",
    "print(f\"Taille du jeu d'entra√Ænement : {len(train_dataset)}\")\n",
    "print(f\"Taille du jeu de test : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu de donn√©es √©tiquet√© : 350\n",
      "Taille du jeu de donn√©es non-√©tiquet√© : 6657\n",
      "Taille du jeu de test : 2005\n"
     ]
    }
   ],
   "source": [
    "# On prend tout le set d'entra√Ænement initial\n",
    "all_indices = list(range(len(train_dataset)))\n",
    "labels_array = np.array(train_dataset.labels).flatten()\n",
    "\n",
    "# S√©lectionner 50 images par classe\n",
    "labeled_indices = []\n",
    "for c in range(n_classes):\n",
    "    class_indices = np.where(labels_array == c)[0]\n",
    "    selected = np.random.choice(class_indices, min(50, len(class_indices)), replace=False)\n",
    "    labeled_indices.extend(selected)\n",
    "\n",
    "# Les indices non √©tiquet√©s sont le reste\n",
    "unlabeled_indices = list(set(all_indices) - set(labeled_indices))\n",
    "\n",
    "# Cr√©ation des Subsets PyTorch\n",
    "labeled_dataset = Subset(train_dataset, labeled_indices)\n",
    "unlabeled_dataset = Subset(train_dataset, unlabeled_indices)\n",
    "\n",
    "print(f\"Taille du jeu de donn√©es √©tiquet√© : {len(labeled_dataset)}\")\n",
    "print(f\"Taille du jeu de donn√©es non-√©tiquet√© : {len(unlabeled_dataset)}\")\n",
    "print(f\"Taille du jeu de test : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders pour SGAN (batch_size plus petit pour stabilit√©)\n",
    "sgan_labeled_loader = DataLoader(labeled_dataset, batch_size=64, shuffle=True)\n",
    "sgan_unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. D√©finition des r√©seaux : g√©n√©rateur et discriminateur\n",
    "\n",
    "Le **g√©n√©rateur (G)** prend du bruit al√©atoire (vecteur de dimension 100) et produit des images 28x28x3.\n",
    "\n",
    "Le **discriminateur (D)** est une variante de notre SimpleCNN : il sort `n_classes + 1` logits (les n_classes premi√®res pour les classes r√©elles, la derni√®re pour 'faux').\n",
    "\n",
    "Rappel : Lors de l'entra√Ænement, D sera corrig√© diff√©remment selon le type d'image :\n",
    "- √âtiquet√©es : Pr√©dire la classe exacte (0-6).\n",
    "- Non √©tiquet√©es : Pr√©dire 'r√©el' (somme probs 0-6 √©lev√©e).\n",
    "- G√©n√©r√©es : Pr√©dire 'faux' (prob 7 √©lev√©e)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©seaux SGAN pr√™ts pour la d√©mo !\n"
     ]
    }
   ],
   "source": [
    "# Dimension du bruit\n",
    "z_dim = 100\n",
    "device = \"cpu\"\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=z_dim, img_channels=3, img_size=28):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, img_size * img_size * img_channels),\n",
    "            nn.Tanh()  # Sorties entre -1 et 1\n",
    "        )\n",
    "        self.img_size = img_size\n",
    "        self.img_channels = img_channels\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), self.img_channels, self.img_size, self.img_size)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7 * 7 * 32, num_classes + 1)  # +1 pour faux\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Instanciation\n",
    "G = Generator().to(device)\n",
    "D = Discriminator(n_channels, n_classes).to(device)\n",
    "\n",
    "# Optimiseurs\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.002, betas=(0.5, 0.999))\n",
    "\n",
    "print('R√©seaux SGAN pr√™ts pour la d√©mo !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. La boucle d'entra√Ænement adversariale\n",
    "\n",
    "Lheart des GANs : une boucle o√π D et G s'affrontent.\n",
    "\n",
    "Rappel de la strat√©gie :\n",
    "- **Pour D sur √©tiquet√©es** : Perte supervis√©e pour pr√©dire la bonne classe (0-6).\n",
    "- **Pour D sur non √©tiquet√©es** : Perte pour pr√©dire 'r√©el' (somme probs 0-6 √©lev√©e).\n",
    "- **Pour D sur g√©n√©r√©es** : Perte pour pr√©dire 'faux' (prob 7 √©lev√©e).\n",
    "- **Pour G** : Perte pour tromper D (faire passer les g√©n√©r√©es pour r√©elles, somme probs 0-6 √©lev√©e).\n",
    "\n",
    "L'entra√Ænement est altern√©. Observez les pertes pour voir l'√©quilibre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entra√Ænement SGAN:  49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                                           | 49/100 [01:45<01:40,  1.98s/it]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 100  # Ajustez pour la d√©mo (plus = mieux, mais plus long)\n",
    "supervised_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Listes pour stocker les pertes moyennes par √©poque\n",
    "epoch_d_losses = []\n",
    "epoch_g_losses = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc='Entra√Ænement SGAN'):\n",
    "    D.train()\n",
    "    G.train()\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "\n",
    "    # It√©rateurs pour √©quilibrer les batches\n",
    "    labeled_iter = iter(sgan_labeled_loader)\n",
    "    unlabeled_iter = iter(sgan_unlabeled_loader)\n",
    "\n",
    "    num_batches = min(len(sgan_labeled_loader), len(sgan_unlabeled_loader))\n",
    "    for batch_idx in range(num_batches):\n",
    "        # Donn√©es √©tiquet√©es\n",
    "        try:\n",
    "            labeled_imgs, labels = next(labeled_iter)\n",
    "        except StopIteration:\n",
    "            labeled_iter = iter(sgan_labeled_loader)\n",
    "            labeled_imgs, labels = next(labeled_iter)\n",
    "        labeled_imgs = labeled_imgs.to(device)\n",
    "        labels = labels.squeeze().long().to(device)\n",
    "\n",
    "        # Donn√©es non √©tiquet√©es\n",
    "        try:\n",
    "            unlabeled_imgs, _ = next(unlabeled_iter)\n",
    "        except StopIteration:\n",
    "            unlabeled_iter = iter(sgan_unlabeled_loader)\n",
    "            unlabeled_imgs, _ = next(unlabeled_iter)\n",
    "        unlabeled_imgs = unlabeled_imgs.to(device)\n",
    "        batch_size = unlabeled_imgs.size(0)\n",
    "\n",
    "        # G√©n√©rer fausses images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake_imgs = G(z)\n",
    "\n",
    "        # --- Entra√Æner D ---\n",
    "        d_optimizer.zero_grad()\n",
    "\n",
    "        # Supervis√© sur r√©elles √©tiquet√©es : corriger pour la bonne classe (0-6)\n",
    "        real_labeled_logits = D(labeled_imgs)\n",
    "        d_sup_loss = supervised_criterion(real_labeled_logits[:, :n_classes], labels)\n",
    "\n",
    "        # Non supervis√© sur r√©elles non √©tiquet√©es : corriger pour 'r√©el' (somme probs 0-6 √©lev√©e)\n",
    "        real_unlabeled_logits = D(unlabeled_imgs)\n",
    "        real_probs = torch.softmax(real_unlabeled_logits, dim=1)[:, :n_classes].sum(1)\n",
    "        d_real_unsup_loss = -torch.log(real_probs + 1e-10).mean()\n",
    "\n",
    "        # Non supervis√© sur fausses : corriger pour 'faux' (prob 7 √©lev√©e)\n",
    "        fake_logits = D(fake_imgs.detach())\n",
    "        fake_probs = torch.softmax(fake_logits, dim=1)[:, n_classes]\n",
    "        d_fake_unsup_loss = -torch.log(fake_probs + 1e-10).mean()\n",
    "\n",
    "        d_loss = d_sup_loss + d_real_unsup_loss + d_fake_unsup_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        d_losses.append(d_loss.item())\n",
    "\n",
    "        # --- Entra√Æner G : corriger pour tromper D (somme probs 0-6 √©lev√©e pour fausses) ---\n",
    "        g_optimizer.zero_grad()\n",
    "\n",
    "        fake_logits_g = D(fake_imgs)\n",
    "        g_fake_probs = torch.softmax(fake_logits_g, dim=1)[:, :n_classes].sum(1)\n",
    "        g_loss = -torch.log(g_fake_probs + 1e-10).mean()\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        g_losses.append(g_loss.item())\n",
    "\n",
    "    # Calculer et stocker les pertes moyennes par √©poque\n",
    "    epoch_d_losses.append(np.mean(d_losses))\n",
    "    epoch_g_losses.append(np.mean(g_losses))\n",
    "\n",
    "# Afficher le graphique des pertes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), epoch_d_losses, label='Perte Discriminateur (D)', marker='o')\n",
    "plt.plot(range(1, num_epochs + 1), epoch_g_losses, label='Perte G√©n√©rateur (G)', marker='s')\n",
    "plt.xlabel('√âpoque')\n",
    "plt.ylabel('Perte moyenne')\n",
    "plt.title('√âvolution des pertes du Discriminateur et du G√©n√©rateur')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. √âvaluation et comparaison\n",
    "\n",
    "Utilisons le Discriminateur comme classificateur : on prend l'argmax sur les n_classes premi√®res sorties.\n",
    "\n",
    "Rappel : Gr√¢ce √† la strat√©gie, D a √©t√© corrig√© sur les √©tiquet√©es (classes exactes), non √©tiquet√©es ('r√©el' vs 'faux'), et g√©n√©r√©es (d√©tection des faux). Cela devrait am√©liorer sa performance en classification.\n",
    "\n",
    "Comparons avec les baselines des chapitres pr√©c√©dents (remplacez les placeholders par vos r√©sultats r√©els)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sgan(model, test_loader, n_classes):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_score_probs = []  # Pour stocker les probabilit√©s pour l'AUC\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            logits = model(images)[:, :n_classes]  # Logits pour les classes r√©elles (0 √† n_classes-1)\n",
    "            probs =nn.functional.softmax(logits, dim=1)  # Convertir en probabilit√©s\n",
    "            preds = torch.argmax(logits, dim=1)  # Pr√©dictions de classe\n",
    "            y_true.extend(labels.cpu().numpy().flatten())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_score_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Convertir en arrays NumPy\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_score_probs = np.array(y_score_probs)\n",
    "\n",
    "    # Calculer les m√©triques\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_score_probs, multi_class='ovr')  # Utiliser probabilit√©s et 'ovr'\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    return acc, auc, f1\n",
    "\n",
    "# Appel de la fonction\n",
    "sgan_acc, sgan_auc, sgan_f1 = evaluate_sgan(D, test_loader, n_classes)\n",
    "print(f'SGAN - Acc: {sgan_acc:.3f}, F1: {sgan_f1:.3f}, AUC: {sgan_auc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation des images g√©n√©r√©es\n",
    "\n",
    "Voyons ce que le G√©n√©rateur a appris ! On g√©n√®re quelques images al√©atoires.\n",
    "\n",
    "Rappel : Ces images sont cr√©√©es pour tromper D, donc si elles ressemblent √† des l√©sions (et forcent D √† les classer en 0-6), G a bien fonctionn√©. Si D les classe en 7, il d√©tecte les faux efficacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gen = 8\n",
    "z = torch.randn(num_gen, z_dim).to(device)\n",
    "gen_imgs = G(z).cpu().detach()\n",
    "gen_imgs = (gen_imgs + 1) / 2  # D√©normaliser [0,1]\n",
    "\n",
    "fig, axes = plt.subplots(1, num_gen, figsize=(15, 3))\n",
    "for i in range(num_gen):\n",
    "    axes[i].imshow(gen_imgs[i].permute(1, 2, 0).numpy())\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Gen {i+1}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion et questions pour la suite\n",
    "\n",
    "Les SGAN d√©montrent comment la g√©n√©ration adversariale peut enrichir l'apprentissage semi-supervis√© en cr√©ant de la vari√©t√©. Rappel de la strat√©gie : Correction pr√©cise sur √©tiquet√©es (classes 0-6), 'r√©el' sur non √©tiquet√©es (somme 0-6), 'faux' sur g√©n√©r√©es (classe 7). Le g√©n√©rateur trompe D pour am√©liorer les deux.\n",
    "\n",
    "Si les images g√©n√©r√©es ressemblent √† des l√©sions cutan√©es, le mod√®le a captur√© des motifs utiles !\n",
    "\n",
    "**Questions pour r√©fl√©chir :**\n",
    "1. **Am√©liorations** : Comment rendre le SGAN conditionnel (cSGAN) pour g√©n√©rer par classe ? Utile pour √©quilibrer les minoritaires ?\n",
    "2. **Stabilit√©** : Les GANs sont instables. Testez avec plus d'√©poques ou WGAN (Wasserstein loss). Qu'observez-vous ?\n",
    "3. **Hybride** : Combinez SGAN avec pseudo-labeling : utilisez les fausses images comme non √©tiquet√©es suppl√©mentaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
