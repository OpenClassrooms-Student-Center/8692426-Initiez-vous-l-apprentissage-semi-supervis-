# **Texte du cours**

# [Initiez-vous Ã  l'apprentissage semi-supervisÃ© ]

**Pour vous aider, voici quelques bonnes pratiques chez OpenClassrooms :** 

* Utilisez le **vouvoiement singulier** : vous parlez Ã  un Ã©tudiant, vous vous adressez directement Ã  lui.

* Pensez **opÃ©rationnel** : lâ€™Ã©tudiant est lÃ  pour acquÃ©rir des compÃ©tences quâ€™il pourra rÃ©utiliser dans le monde du travail : soyez donc pragmatique et apportez-lui des informations, techniques, procÃ©dures concrÃ¨tes. 

* Restez **simple** : ne pas simplifier Ã  l'extrÃªme, mais faciliter la tÃ¢che des apprenants. Visez la clartÃ©. Faites des phrases courtes. DÃ©finissez les nouveaux termes. Pensez Ã  la faÃ§on dont le cours sera utilisÃ© par lâ€™apprenant, Ã  la fois comme expÃ©rience d'apprentissage en direct et comme rÃ©fÃ©rence ultÃ©rieure. Dans chaque chapitre, divisez votre contenu en sections thÃ©matiques. Il est ainsi plus facile pour les apprenants de retenir les connaissances, d'organiser leur prise de notes Ã©ventuelle et de se rÃ©fÃ©rer au contenu en cas de besoin.

* **Structurez votre chapitre :** Il est souvent utile d'aborder chaque chapitre en commenÃ§ant par le pourquoi, puis le quoi, puis le comment.   
  En d'autres termes : Nous devrions apprendre immÃ©diatement pourquoi nous devrions terminer ce chapitre.  Quel est le problÃ¨me que ce chapitre nous aidera Ã  rÃ©soudre ? Quelles sont les informations essentielles dont nous avons besoin pour rÃ©soudre le problÃ¨me ? Comment le rÃ©soudre ? Quel est le processus de rÃ©solution ? Veillez Ã  fournir un exercice pour mettre ce processus en pratique.

* **Utilisez des transitions**, en soulignant la faÃ§on dont les compÃ©tences s'appuient les unes sur les autres, en particulier au dÃ©but de chaque chapitre, mais aussi Ã  la fin de chaque partie et Ã  la fin du cours. Que sommes-nous dÃ©sormais capables de faire et quelle est la prochaine Ã©tape Ã  franchir pour continuer Ã  progresser ?

**Dans le corps du texte, vous avez la possibilitÃ© de mettre en avant visuellement des encarts avec de la couleur pour  :** 

//bleu clair 3//

**Donner une information** : (dÃ©finition, apport de contexte, complÃ©ment dâ€™information, ressources Ã  consulterâ€¦

//orange clair 3//

**Apporter un point de vigilance** 

//rouge clair 3//

**Montrer un exemple dâ€™erreur** ou un interdit

//gris clair 2//

**Poser une question** : on se met Ã  la place de l'Ã©tudiant : une question qu'il pourrait se poser en lisant â€œMais comment on fait cela ?â€ ; â€œMais Ã  quoi cela sert-il ?â€ â€¦ 

Pour les questions posÃ©es de votre point de vue d'expert, n'utilisez pas cette mise en forme. Par exemple, vous pouvez demander Ã  lâ€™apprenant de rÃ©flÃ©chir Ã  quelque chose avant de poursuivre sa lecture. C'est une excellente faÃ§on d'impliquer lâ€™apprenant, mais ce n'est pas la raison d'Ãªtre de cet encadrÃ© gris.

* | *Citer une phrase et/ou donner un exemple.*

**Si vous Ã©crivez un cours sur la programmationâ€¦**

* Indiquez le **code in-line** (qui apparaÃ®t dans le texte directement) en formattant le texte avec la police `Roboto Mono`.

* Pour indiquer un **extrait de code**, 

  * ajoutez une ligne de trois backquotes avant et aprÃ¨s le code, 

  * prÃ©cisez entre parenthÃ¨ses, en amont du code, le langage utilisÃ©.

\`\`\`(javascript)

\[le code\]

\`\`\`

| Pour plus dâ€™informations, vous pouvez consulter cette page : [Conseils de rÃ©daction du cours](https://openclassrooms.notion.site/R-daction-du-cours-5bdf2035acdf481480934da87c998853) |
| :---- |

**1500 mots maximum** par chapitre (Pour compter les mots du Google Doc : sÃ©lectionner le chapitre concernÃ© puis cliquer sur outil \> nombre de mot ; une fenÃªtre sâ€™ouvre et affiche le nombre sÃ©lectionnÃ© sur le total de mot du document. ğŸ“Š

# **Introduction**

###### #TLK - Teaser 

Les donnÃ©es brutes existent en masse. Or, la plupart de ces donnÃ©es n'est pas labellisÃ©e. Comment entraÃ®ner une IA dans ces conditions ? ğŸ¤”

Câ€™est exactement le dÃ©fi des data scientists aujourd'hui. Les donnÃ©es ? Abondantes. Mais les annotations sont rares et coÃ»teuses : il faut du temps, de la prÃ©cision et de l'expertise pour les ajouter. â±ï¸ğŸ’¸

C'est lÃ  qu'entre en jeu lâ€™**apprentissage semi-supervisÃ©** ou SSL (*Semi Supervised Learning* en anglais). ğŸš€

Entre le tout-Ã©tiquetÃ© du supervisÃ© et le zÃ©ro-Ã©tiquette du non supervisÃ©, le semi-supervisÃ© utilise les deux : il apprend Ã  partir dâ€™un petit Ã©chantillon bien annotÃ©â€¦ pour mieux exploiter la masse restante. âš–ï¸ğŸ§ 

RÃ©sultat ? Moins dâ€™Ã©tiquettes, mais des modÃ¨les puissants, capables dâ€™analyser des images mÃ©dicales avec prÃ©cision. ğŸ¯

Dans ce cours, vous construirez un modÃ¨le de segmentation semi-supervisÃ© pour analyser des images radiologiques. ğŸ©»

Envie de plonger au cÅ“ur de lâ€™IA, mÃªme quand elle nâ€™a pas toutes les rÃ©ponses ? Commencez le cours dÃ¨s maintenant ! ğŸŠâ€â™€ï¸ğŸ¤–

 **PrÃ©requis, outils :** 

Pour suivre ce cours, vous devez Ãªtre Ã  lâ€™aise avec Python et les bases du machine learning (classification, surâ€‘apprentissage, mÃ©triques), et vous aurez besoin de maÃ®triser ces outils : 
//bleu clair 3//
* [scikit-learn](https://scikit-learn.org/stable/)  
* [TensorFlow](https://www.tensorflow.org/?hl=fr)  
* [PyTorch](https://pytorch.org/)  
* [OpenCV](https://opencv.org/)

Par ailleurs, avant de vous lancer dans lâ€™apprentissage semi-supervisÃ©, il est prÃ©fÃ©rable dâ€™avoir suivi au prÃ©alable les cours suivants : 

* [Initiez-vous au Machine Learning](https://openclassrooms.com/fr/courses/8063076-initiez-vous-au-machine-learning)  
* [MaÃ®trisez l'apprentissage supervisÃ©](https://openclassrooms.com/fr/courses/8431846-maitrisez-lapprentissage-supervise)  
* [ApprÃ©hendez les enjeux mÃ©tier de lâ€™apprentissage supervisÃ©](https://openclassrooms.com/fr/courses/8468461-apprehendez-les-enjeux-metier-de-l-apprentissage-supervise)

\[lister les prÃ©-requis et outils\].

# **Mettez en place un modÃ¨le semi-supervisÃ©**

### P1C1 : Tirez un maximum de ce cours

> Email â€” Emma (PM)
>
> Objet: Kick-off Hackathon MedTech (48h)
>
> Bonjour l'Ã©quipe,
>
> Notre dÃ©fi: livrer un POC dâ€™aide au tri dermatologique en 48h. Beaucoup dâ€™images, peu dâ€™annotations. Objectif: une dÃ©mo fluide avec des mÃ©triques crÃ©dibles (AUC/F1) et une narration claire. On priorise des incrÃ©ments Ã  fort impact, reproductibles et prÃ©sentables. Go!
>
//bleu clair 3//
**Brief produit (extrait documentation projet)**
- ProblÃ¨me: peu de labels, masse dâ€™images Ã  trier.
- Contraintes: temps, budget, sÃ©curitÃ© patient.
- CritÃ¨res de succÃ¨s: uplift mesurable + dÃ©mo stable.
- Approche: SSL (pseudo-labeling, graphes, cohÃ©rence, SGAN en option).

//orange clair 3//
**Note clinique â€” Dr Malik**
- Classes sensibles: erreurs coÃ»teuses (fausses rassurances).
- Exigences: transparence, calibration, pilotage par seuils.

#### DÃ©couvrez lâ€™objectif du cours

Dans ce cours, vous allez comprendre quand et pourquoi utiliser lâ€™apprentissage semi-supervisÃ© (SSL) et apprendre Ã  lâ€™implÃ©menter en Python pour des problÃ¨mes dâ€™imagerie mÃ©dicale. Ã€ la fin, vous saurez : ğŸ˜

- Identifier les situations oÃ¹ les labels manquent et oÃ¹ le SSL apporte un gain concret. ğŸ”
- Mettre en place un pipeline de pseudo-labeling avec PyTorch. ğŸ§ª
- Exploiter la structure des donnÃ©es via la propagation dâ€™Ã©tiquettes sur graphe. ğŸ•¸ï¸
- Comprendre le principe des SGANs et de la rÃ©gularisation par cohÃ©rence pour stabiliser les prÃ©dictions. ğŸ§˜â€â™‚ï¸

#### Rencontrez votre professeur

MEET YOUR TEACHER VIDEO

Expert en analyse de donnÃ©es, AurÃ©lien Quillet a commencÃ© sa carriÃ¨re en dÃ©veloppant des outils de bio-informatique avant de se spÃ©cialiser dans l'apprentissage automatique (Machine Learning). Cette Ã©volution lui a permis d'acquÃ©rir une solide expÃ©rience dans l'utilisation des tests statistiques et des probabilitÃ©s au travers de divers projets professionnels couvrant diffÃ©rents secteurs (biologie, finance, marketing, etc.). Formateur depuis 2020, AurÃ©lien Quillet est passionnÃ© par le partage de ces connaissances essentielles au dÃ©veloppement optimal des entreprises.

#### DÃ©couvrez le fonctionnement du cours

Connaissez-vous le principe d'un cours en ligne sur OpenClassrooms ? Ce cours suit une progression logique que l'on a sÃ©quencÃ©e en plusieurs chapitres, qu'il est prÃ©fÃ©rable de suivre dans l'ordre. ğŸ“š

Dans ces chapitres, vous trouverez :

* du **texte** avec des explications et des exemples concrets, pour prÃ©senter des outils spÃ©cifiques et lister des ressources externes Ã  consulter ou encore des fichiers Ã  tÃ©lÃ©charger ;  
* des **tutoriels vidÃ©os** permettant de suivre Ã©tape par Ã©tape la rÃ©alisation du projet fil rouge directement sur l'Ã©cran de lâ€™expert formateur. Les Ã©tapes et les lignes de code vous sont prÃ©sentÃ©es grÃ¢ce Ã  Google Colab. Google Colab est un environnement en ligne gratuit pour exÃ©cuter du code Python dans des notebooks Jupyter. Notez que les rÃ©sultats obtenus dans le texte et les screencasts peuvent lÃ©gÃ¨rement varier Ã  l'exÃ©cution des scripts.

Les sections "Ã€ vous de jouer" sont l'occasion de mettre en pratique ; câ€™est lÃ  que vous suivrez notamment les dÃ©monstrations en vidÃ©o et que vous pourrez reproduire.

Ã€ la fin du cours, vous trouverez un **quiz** pour vous permettre de valider ce que vous avez appris. ğŸ§ªâœ…

Certains blocs de code contiennent des **lignes tronquÃ©es**. Pas d'inquiÃ©tude, il n'y a pas d'erreurs. Si vous cliquez sur le bloc de code en question, l'intÃ©gralitÃ© de celui-ci apparaÃ®tra correctement. ğŸ’¡

Avant de dÃ©marrer, voici quelques conseils pour exploiter au mieux le contenu de ce cours et **optimiser votre apprentissage** :

1. Lisez le texte dans chaque chapitre pour comprendre **pourquoi** les concepts abordÃ©s sont importants.  
2. Suivez les dÃ©monstrations pour savoir **comment** vous pouvez mettre en Å“uvre ces concepts.  
3. Profitez de chaque occasion de pratiquer en faisant une pause dans le cours, pour vous entraÃ®ner de votre cÃ´tÃ© et reproduire pas Ã  pas ce que vous avez appris.

#### DÃ©couvrez le projet fil rouge du cours ğŸ§µ

Tout au long du cours, vous allez mettre en place des techniques semi-supervisÃ©es sur un dataset mÃ©dical standardisÃ©. Nous utiliserons `DermaMNIST` (famille MedMNIST) pour illustrer la classification avec peu dâ€™images Ã©tiquetÃ©es et un grand volume non Ã©tiquetÃ©. Vous pourrez ensuite transposer ces techniques Ã  un contexte de segmentation radiologique.

#### TÃ©lÃ©chargez la fiche rÃ©sumÃ© du cours ğŸ“

COURSE SUMMARY  

*PrÃªt Ã  dÃ©marrer ? On pose les bases du semiâ€‘supervisÃ© juste aprÃ¨s ğŸ§­* 

### P1C2  : DÃ©couvrez le principe de lâ€™apprentissage semi supervisÃ© ğŸ§­

//bleu clair 3//
**Note technique (panorama SSL)**
- Pseudoâ€‘labeling: rapide, simple, sensible au seuil.
- Graphes (LabelSpreading): exploite la structure globale.
- CohÃ©rence (Mean Teacher / UDA / FixMatch): stabilitÃ© et calibration.
- SGAN: renforce le discriminateur via une classe supplÃ©mentaire (K+1).

//gris clair 2//
**Decision log #1**
- DÃ©cision: dÃ©marrer par pseudoâ€‘labeling pour un gain rapide.
- PrÃ©voir LabelSpreading pour capturer la structure.
- Garder SGAN pour un effet diffÃ©renciant si timing OK.
- Justification: coÃ»t/valeur/risques au format hackathon.

//orange clair 3//
**Alerte**: calibration et fuite dâ€™info. Toujours valider sur un test set tenu Ã  lâ€™Ã©cart.

#### Rappelez-vous des principes du supervisÃ© vs non supervisÃ©

Le supervisÃ© apprend Ã  partir de paires `(x, y)` et nÃ©cessite beaucoup dâ€™annotations. Le non supervisÃ© apprend des structures sans Ã©tiquettes. Le semi-supervisÃ© combine un petit ensemble annotÃ© avec un large ensemble non annotÃ© pour amÃ©liorer la gÃ©nÃ©ralisation Ã  moindre coÃ»t. âš™ï¸

//orange clair 3//
**Point de vigilance**: les erreurs de pseudo-labels peuvent se propager. Gardez des seuils de confiance et Ã©valuez rÃ©guliÃ¨rement sur un jeu de test labellisÃ©. âš ï¸

#### Comprenez lâ€™intÃ©rÃªt de lâ€™apprentissage semi-supervisÃ©

- RÃ©duire le coÃ»t dâ€™annotation (experts rares en mÃ©dical). ğŸ’¸
- Mieux exploiter la masse de donnÃ©es disponibles en production. ğŸ“ˆ
- AmÃ©liorer la robustesse et la calibration des modÃ¨les quand les labels sont bruyants ou partiels. ğŸ›¡ï¸

#### Comprenez les principes fondamentaux du semi-supervisÃ©

- Pseudo-labeling: utiliser les prÃ©dictions les plus confiantes comme labels temporaires. ğŸ·ï¸
- MÃ©thodes par graphe: propager lâ€™information des nÅ“uds labellisÃ©s vers leurs voisins dans un espace de similaritÃ©. ğŸ•¸ï¸
- RÃ©gularisation par cohÃ©rence: forcer des prÃ©dictions stables malgrÃ© de petites perturbations (Mean Teacher, UDA). ğŸ”

#### En rÃ©sumÃ© 

* Le SSL tire parti des donnÃ©es non Ã©tiquetÃ©es pour renforcer lâ€™apprentissage.
* Des seuils et une Ã©valuation continue sont indispensables.
* Plusieurs familles de mÃ©thodes existent et sont complÃ©mentaires.

*Dans le prochain chapitre, vous verrez comment implÃ©menter pas Ã  pas le pseudo-labeling en PyTorch.* ğŸ‘‰

### P1C3 : CatÃ©gorisez lâ€™inconnu avec la pseudo labellisation ğŸ§ª

//bleu clair 3//
**Playbook â€” Pseudoâ€‘labeling (documentation projet)**
1. EntraÃ®ner un modÃ¨le de base sur peu de labels.
2. PrÃ©dire sur non Ã©tiquetÃ©es + softmax.
3. SÃ©lectionner auâ€‘dessus dâ€™un seuil (confiance/Ã©cart topâ€‘1 vs topâ€‘2).
4. Ajouter ces exemples Ã  lâ€™entraÃ®nement.
5. RÃ©entraÃ®ner, surveiller AUC/F1.

> Email â€” Emma
>
> Point intermÃ©diaire: prioritÃ© Ã  un uplift tangible, pas de surâ€‘promesse. Partagez vos seuils et dÃ©cisions dans la doc.

//orange clair 3//
**Alerte**: biais de confirmation. Un seuil trop bas inonde de bruit.

//gris clair 2//
**Decision log #2**
- Seuil initial: 0.90
- ItÃ©rations: 5
- ArrÃªt: si plus de candidats auâ€‘dessus du seuil.

#### Ã‰tablissez des prÃ©dictions fiables (Principe et algorithme)

Le pseudo-labeling consiste Ã  prÃ©dire sur les donnÃ©es non Ã©tiquetÃ©es, sÃ©lectionner les prÃ©dictions au-dessus dâ€™un seuil de confiance, les ajouter Ã  lâ€™entraÃ®nement comme labels temporaires, puis rÃ©entraÃ®ner le modÃ¨le. Câ€™est la version Â« coach confiant Â» de lâ€™apprentissage. ğŸ’¬ğŸ’ª

```python
# Imports et prÃ©paration (PyTorch, MedMNIST)
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Subset
import medmnist
from medmnist import INFO
from torchvision import transforms

data_flag = 'dermamnist'
info = INFO[data_flag]
DataClass = getattr(medmnist, info['python_class'])
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([.5],[.5])])
train_dataset = DataClass(split='train', transform=transform, download=True)
test_dataset = DataClass(split='test', transform=transform, download=True)

# SÃ©lectionner 50 images par classe (350 labels)
n_classes = len(info['label'])
labels_array = np.array(train_dataset.labels).flatten()
labeled_indices = []
for c in range(n_classes):
    idx = np.where(labels_array == c)[0]
    labeled_indices.extend(np.random.choice(idx, min(50, len(idx)), replace=False))
unlabeled_indices = list(set(range(len(train_dataset))) - set(labeled_indices))

labeled_loader = DataLoader(Subset(train_dataset, labeled_indices), batch_size=16, shuffle=True)
unlabeled_loader = DataLoader(Subset(train_dataset, unlabeled_indices), batch_size=128, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)

# Petit CNN et boucle d'entraÃ®nement
class SimpleCNN(nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(in_channels, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.fc = nn.Linear(7*7*32, num_classes)
    def forward(self, x):
        x = self.layer1(x); x = self.layer2(x); x = x.view(x.size(0), -1); return self.fc(x)

def get_pseudo_labels(model, unlabeled_loader, threshold=0.9):
    model.eval(); indices, labels = [], []
    with torch.no_grad():
        for i, (images, _) in enumerate(unlabeled_loader):
            probs = torch.softmax(model(images), dim=1)
            max_p, preds = probs.max(dim=1)
            mask = max_p > threshold
            start = i * unlabeled_loader.batch_size
            batch_idx = torch.arange(start, start + images.size(0))
            original = [unlabeled_loader.dataset.indices[j] for j in batch_idx[mask]]
            indices.extend(original); labels.extend(preds[mask].tolist())
    return indices, labels
```

#### DÃ©couvrez un cas dâ€™usage

Appliquez le pseudo-labeling sur `DermaMNIST` avec 350 images Ã©tiquetÃ©es. Ã€ chaque itÃ©ration, ajoutez les plus confiantes des non Ã©tiquetÃ©es et rÃ©entraÃ®nez.

```python
device = torch.device('cpu')
model = SimpleCNN(in_channels=info['n_channels'], num_classes=n_classes).to(device)
opt = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

current = list(labeled_indices)
for it in range(5):
    train_loader = DataLoader(Subset(train_dataset, current), batch_size=32, shuffle=True)
    # EntraÃ®ner quelques Ã©poques sur les labels courants...
    for epoch in range(5):
        model.train()
        for x, y in train_loader:
            y = y.squeeze().long()
            opt.zero_grad(); loss = criterion(model(x), y); loss.backward(); opt.step()
    # GÃ©nÃ©rer des pseudo-labels
    pseudo_idx, pseudo_y = get_pseudo_labels(model, unlabeled_loader, threshold=0.9)
    for idx, yhat in zip(pseudo_idx, pseudo_y):
        if idx not in current:
            train_dataset.labels[idx] = yhat
            current.append(idx)
```

//rouge clair 3//
**Erreur classique**: baisser trop le seuil introduit du bruit et dÃ©grade les performances. ğŸ§¯

#### Comprenez les avantages et les piÃ¨ges du pseudo-labeling

- Avantages: simple, exploite immÃ©diatement les donnÃ©es non Ã©tiquetÃ©es.
- PiÃ¨ges: propagation dâ€™erreurs, biais de confirmation, sensibilitÃ© au seuil et Ã  la calibration.

#### Ã€ vous de jouer ğŸ¯

DÃ©finissez les critÃ¨res (mÃ©triques et seuils) pour dÃ©cider si un pseudo-label est suffisamment fiable (ex. seuil de probabilitÃ©, marge top-1/top-2, calibration prÃ©alable) et justifiez vos choix.

#### En rÃ©sumÃ© 

* Le pseudo-labeling est un point dâ€™entrÃ©e efficace et simple au SSL.
* La sÃ©lection par confiance et la calibration sont cruciales.
* RÃ©entraÃ®nez par itÃ©rations en surveillant les mÃ©triques de test.

*Et si vos images se donnaient des tuyaux entre voisines ? Place aux graphes ğŸ•¸ï¸*

### P1C4 : ModÃ©lisez les relations entre diffÃ©rentes entitÃ©s ğŸ•¸ï¸

//bleu clair 3//
**Note technique â€” Graphes et propagation**
- Embeddings via CNN (features): compacter lâ€™information.
- Graphe kâ€‘NN: relier les images proches.
- LabelSpreading: diffuser les labels connus vers les voisins.

//bleu clair 3//
**â€œDiagrammeâ€ (texte)**
- NÅ“uds = images, ArÃªtes = similaritÃ©s
- Sources = labels connus â†’ diffusion â†’ labels pour les autres nÅ“uds

//orange clair 3//
**Alerte**: embeddings faibles â†’ propagation mÃ©diocre. Soignez lâ€™extraction.

//gris clair 2//
**Decision log #3**
- ParamÃ¨tres initiaux: k=10, kernel=knn
- Ã‰valuation: AUC (OvR) + F1 macro sur non Ã©tiquetÃ©es

#### DÃ©couvrez le principe dâ€™un graphe

On construit un graphe de similaritÃ© entre images (nÅ“uds) et on propage lâ€™information des quelques nÅ“uds labellisÃ©s vers les autres. La sagesse des voisins au service de la prÃ©diction ! ğŸ§‘â€ğŸ¤â€ğŸ§‘

#### Propagez des labels aux nÅ“uds non labellisÃ©s

```python
from sklearn.semi_supervised import LabelSpreading
from torch.utils.data import DataLoader

# Extraire des embeddings avec le CNN appris
def get_embeddings(model, dataset, device):
    model.eval(); embs = []
    loader = DataLoader(dataset, batch_size=256, shuffle=False)
    with torch.no_grad():
        for x, _ in loader:
            feats = model.layer2(model.layer1(x))
            feats = feats.view(feats.size(0), -1)
            embs.append(feats.numpy())
    import numpy as np; return np.vstack(embs)

embeddings = get_embeddings(model, train_dataset, device)
labels_for_spread = np.full(len(train_dataset), -1)
labels_for_spread[labeled_indices] = labels_array[labeled_indices]

spreader = LabelSpreading(kernel='knn', n_neighbors=10)
spreader.fit(embeddings, labels_for_spread)
pred_labels = spreader.transduction_
```

#### DÃ©couvrez un cas dâ€™usage

Sur `DermaMNIST`, la propagation donne un Ã©tiquetage global cohÃ©rent. Comparez accuracy/F1 sur les exemples initialement non Ã©tiquetÃ©s pour juger de lâ€™apport par rapport au pseudo-labeling.

#### Ã€ vous de jouer

ImplÃ©mentez `LabelSpreading` sur vos donnÃ©es, puis Ã©valuez la qualitÃ© de lâ€™Ã©tiquetage obtenu. Quelles valeurs de `n_neighbors` et de noyau (rbf vs knn) fonctionnent le mieux ?

#### En rÃ©sumÃ© 

* Les graphes exploitent la structure globale des donnÃ©es. ğŸŒ
* De bons embeddings amÃ©liorent fortement les rÃ©sultats. ğŸ’ª
* Validez sur des labels tenus Ã  lâ€™Ã©cart pour Ã©viter la fuite dâ€™information. ğŸ”’

*Envie d'apprendre en jouant au chat et Ã  la souris ? Direction les GANs ğŸ­*

### P1C5 : Classifiez des donnÃ©es non-Ã©tiquetÃ©es avec un gÃ©nÃ©rateur et un discriminateur ğŸ­

//bleu clair 3//
**Brief produit â€” SGAN**
- But: enrichir la reprÃ©sentation; D devient classificateur K+1.
- DonnÃ©es: Ã©tiquetÃ©es (supervisÃ©), non Ã©tiquetÃ©es (rÃ©el), gÃ©nÃ©rÃ©es (faux).

//bleu clair 3//
**Note technique**
- D: K classes rÃ©elles + 1 â€œfauxâ€.
- G: gÃ©nÃ©rer des â€œvraiesâ€‘semblancesâ€.
- Risques: instabilitÃ©; monitorer pertes.

//bleu clair 3//
**Checklist QA â€” Hugo (MLOps)**
- Versionner seeds, checkpoints, courbes de pertes.
- Conserver un plan B (arrÃªt anticipÃ© si instable).

//orange clair 3//
**Alerte**: nâ€™investissez pas tout le temps ici si lâ€™entraÃ®nement diverge. PrioritÃ© Ã  une dÃ©mo stable.

#### DÃ©couvrez le fonctionnement du gÃ©nÃ©rateur et du discriminateur (rappel GAN)

Un GAN oppose un GÃ©nÃ©rateur (G) qui synthÃ©tise des images Ã  un Discriminateur (D) qui distingue vrai/faux. En semi-supervisÃ© (SGAN), D prÃ©dit Ã  la fois la classe (0..Kâˆ’1) pour les vraies images et une classe supplÃ©mentaire K pour les fausses.

#### Comprenez le rÃ´le Ã©tendu du discriminateur (SGAN)

- DonnÃ©es Ã©tiquetÃ©es: perte supervisÃ©e sur la classe vraie.
- DonnÃ©es non Ã©tiquetÃ©es: encourager D Ã  prÃ©dire une classe rÃ©elle (0..Kâˆ’1) plutÃ´t que la classe K.
- Images gÃ©nÃ©rÃ©es: D doit prÃ©dire la classe K (fausse).
- G cherche Ã  produire des images que D classe comme rÃ©elles (0..Kâˆ’1).

#### Utilisez des SGANs ğŸ¤

StratÃ©gie pratique: rÃ©utilisez votre pipeline de chargement (`labeled_loader`, `unlabeled_loader`) et entraÃ®nez D avec des tÃªtes adaptÃ©es (`K+1` sorties). Ã‰valuez D comme classificateur sur le test set et comparez aux mÃ©thodes prÃ©cÃ©dentes.

#### Ã€ vous de jouer

Recherchez un exemple SGAN sur images mÃ©dicales. Identifiez les composants clÃ©s (G, D, pertes) et expliquez comment les donnÃ©es Ã©tiquetÃ©es vs non Ã©tiquetÃ©es sont intÃ©grÃ©es.

#### En rÃ©sumÃ© 

* Les SGANs tirent parti des donnÃ©es non Ã©tiquetÃ©es via la tÃ¢che auxiliaire vrai/faux.
* Le discriminateur devient un classificateur amÃ©liorÃ© avec `K+1` classes.
* La stabilitÃ© dâ€™entraÃ®nement et la qualitÃ© des images gÃ©nÃ©rÃ©es sont critiques.

*Stabilisons tout Ã§a avec un peu de zen : la cohÃ©rence arrive ğŸ”*

### P1C6 : Maintenez des prÃ©dictions stables avec la rÃ©gularisation par cohÃ©rence ğŸ”

//bleu clair 3//
**Playbook â€” RÃ©gularisation par cohÃ©rence**
- Vues faibles/fortes: mÃªmes labels attendus.
- Augmentations rÃ©alistes: rotations lÃ©gÃ¨res, contrastes.
- Seuil de confiance: gÃ©nÃ©rer des pseudoâ€‘labels pour vues faibles (esprit FixMatch).

//bleu clair 3//
**Note clinique â€” Dr Malik**
- Ã‰viter les transformations non plausibles en dermato.
- Viser une robustesse â€œdÃ©moâ€‘proofâ€.

//bleu clair 3//
**Checklist dÃ©mo**
- Latence acceptable
- PrÃ©dictions stables Ã  perturbations mineures
- Visualisations lisibles pour le pitch

#### Comprenez le principe de la rÃ©gularisation par cohÃ©rence

Objectif: des prÃ©dictions stables quand on applique de petites perturbations (augmentations) aux entrÃ©es. Exemples: Mean Teacher, UDA/FixMatch (consistance forte/faible). ğŸ§˜â€â™€ï¸

#### DÃ©couvrez un cas dâ€™usage

En radiologie, la cohÃ©rence aux lÃ©gÃ¨res rotations/contrastes amÃ©liore la robustesse. On pÃ©nalise la divergence entre prÃ©dictions sur une image et sa version augmentÃ©e.

#### Appliquez des mÃ©thodes de perturbation des donnÃ©es

- Augmentations gÃ©omÃ©triques: rotation faible, flip, lÃ©ger zoom.
- Augmentations photomÃ©triques: luminositÃ©/contraste, jitter de couleur.
- Seuil de confiance pour gÃ©nÃ©rer des pseudo-labels sur les vues faibles (FixMatch).

#### Ã€ vous de jouer

Imaginez un pipeline de rÃ©gularisation par cohÃ©rence adaptÃ© Ã  vos images (types dâ€™augmentations, intensitÃ©s, seuils). Justifiez vos choix.

#### En rÃ©sumÃ© 

* La cohÃ©rence rÃ©duit le sur-apprentissage et amÃ©liore la calibration. ğŸ›ï¸
* Combinez cohÃ©rence + pseudo-labeling pour de meilleurs rÃ©sultats. ğŸ§©
* Choisissez des augmentations rÃ©alistes par rapport au domaine. ğŸ–¼ï¸

*PrÃªt pour le niveau expert ? On passe Ã  la vitesse supÃ©rieure ğŸš€*

### P1C7 : Allez plus loin ğŸš€

> Email â€” Emma â†’ stakeholders
>
> Objet: DÃ©mo POC â€” SynthÃ¨se et prochaines Ã©tapes
>
> Bonjour,
>
> Le POC dâ€™aide au tri dermatologique est prÃªt pour la dÃ©mo: rÃ©sultats consolidÃ©s, documentation de nos dÃ©cisions (thresholds, propagation, cohÃ©rence), et risques identifiÃ©s. Nous proposons une roadmap: amÃ©liorer les embeddings, intÃ©grer FixMatch/FlexMatch, et cadrer une validation clinique.
>
//bleu clair 3//
**Documentation projet â€” Sommaire**
- Briefs produits
- Notes techniques (SSL, graphes, cohÃ©rence, SGAN)
- Decision logs (#1â€“#3)
- Checklists (QA, dÃ©mo)
- Alerte & vigilance clinique

[TLK]

#### Techniques avancÃ©es

- FixMatch/FlexMatch: pseudo-labels Ã  haute confiance + consistance forte/faible. ğŸ§±
- Self-training avec calibration et stratÃ©gies dâ€™Ã©chantillonnage par incertitude. ğŸ¯
- Meilleurs extracteurs: ResNet/ViT prÃ©-entraÃ®nÃ©s pour des embeddings plus discriminants. ğŸ§ 

#### DÃ©fis restants

- Robustesse aux outliers et au dÃ©calage de domaine. ğŸ›¡ï¸
- Ã‰quitÃ© et biais en santÃ© (distribution des classes, dÃ©mographie). âš–ï¸
- Ã‰valuation fiable quand les labels sont rares (protocoles dâ€™annotation). ğŸ“

#### Perspectives

- IntÃ©gration de lâ€™auto-supervisÃ© (SimCLR/BYOL) au SSL. ğŸ”—
- Few-shot et mÃ©ta-apprentissage pour donnÃ©es rares. ğŸ§­
- Pipelines hybrides: graphes + consistance + pseudo-labels. ğŸ§¬

#### En rÃ©sumÃ© 